from __future__ import print_function

import os
import logging
from queue import Queue
import signal
from signal import pause
import threading
import time
import wave

from pydub import AudioSegment
from pydub.playback import play

import alsaaudio
from gpiozero import Button
from openai import OpenAI

# # # #
#
# Raspberry pi Code
#
# # # #

# å£°å¡ä¸Šçš„æŒ‰é’®å¯¹åº”çš„BCMå¼•è„šå·
button = Button(17)
# é»˜è®¤å£°å¡
device = 'default'
# è®¾ç½®è§¦å‘é•¿æŒ‰äº‹ä»¶çš„æ—¶é—´é˜ˆå€¼
button.hold_time = 1.0  # é•¿æŒ‰æ—¶é—´è®¾ç½®ä¸º1ç§’
# é€€å‡ºäº‹ä»¶
exit_event = threading.Event()

msg = [
    {"role": "system", "content": "è¯·ä½¿ç”¨æ›´ç®€æ´çš„è¯­å¥å›ç­”æˆ‘çš„é—®é¢˜ã€‚"},
    {"role": "user", "content": "ä½ å¥½ã€‚ä»Šå¤©çš„å¤©æ°”é’ˆä¸æˆ³ï¼ğŸ˜ğŸ˜ğŸ˜"}
]

"""
å½•éŸ³æ–¹æ³•
"""


def recoding():
    global recording_stopped

    # ä½¿ç”¨å“ˆå¸Œå€¼ä½œä¸ºæ–‡ä»¶å
    hash_filename = "./static/temp/" + hash(time.time()).__str__() + ".wav"

    f = wave.open(hash_filename, 'wb')

    # Open the device in nonblocking capture mode. The last argument could
    # ä»¥éé˜»å¡æ•æ‰æ¨¡å¼æ‰“å¼€è®¾å¤‡ã€‚æœ€åä¸€ä¸ªå‚æ•°ä¹Ÿå¯ä»¥æ˜¯
    # just as well have been zero for blocking mode. Then we could have
    # é›¶ï¼Œä»£è¡¨é˜»å¡æ¨¡å¼ã€‚é‚£æ ·æˆ‘ä»¬å°±å¯ä»¥ä¸å¿…è¦
    # left out the sleep call in the bottom of the loop
    # åœ¨å¾ªç¯åº•éƒ¨æ”¾ç½®sleepè°ƒç”¨
    inp = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NONBLOCK, channels=1, rate=16000,
                        format=alsaaudio.PCM_FORMAT_S16_LE, periodsize=160, device=device)

    f.setnchannels(1)
    f.setsampwidth(2)  # PCM_FORMAT_S16_LE remains the same as it represents 16-bit sample width
    f.setframerate(16000)

    # print('%d channels, %d sampling rate\n' % (f.getnchannels(), f.getframerate()))
    # The period size controls the internal number of frames per period.
    # å‘¨æœŸå¤§å°æ§åˆ¶æ¯å‘¨æœŸçš„å†…éƒ¨å¸§æ•°ã€‚
    # The significance of this parameter is documented in the ALSA api.
    # è¿™ä¸ªå‚æ•°çš„é‡è¦æ€§åœ¨ALSA apiæ–‡æ¡£ä¸­æœ‰è¯´æ˜ã€‚
    # For our purposes, it is suficcient to know that reads from the device
    # å¯¹æˆ‘ä»¬æ¥è¯´ï¼Œåªéœ€çŸ¥é“ä»è®¾å¤‡è¯»å–
    # will return this many frames. Each frame being 2 bytes long.
    # å°†è¿”å›è¿™ä¹ˆå¤šå¸§ã€‚æ¯ä¸ªå¸§æ˜¯2å­—èŠ‚é•¿ã€‚
    # This means that the reads below will return either 320 bytes of data
    # è¿™æ„å‘³ç€ä¸‹é¢çš„è¯»å–å°†è¿”å›320å­—èŠ‚çš„æ•°æ®
    # or 0 bytes of data. The latter is possible because we are in nonblocking
    # æˆ–è€…0å­—èŠ‚çš„æ•°æ®ã€‚åè€…æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¤„äºéé˜»å¡
    # mode.
    # æ¨¡å¼ã€‚

    while not recording_stopped:
        # Read data from device (è®¾å¤‡è¯»å–æ•°æ®)
        l, data = inp.read()

        if l:
            f.writeframes(data)
            time.sleep(.001)

    f.close()

    return hash_filename


"""
æ’­æ”¾æ–¹æ³•
"""


def play_result(file_path):
    song = AudioSegment.from_mp3(file_path)
    play(song)


"""
ç»“æŸå½•åˆ¶æ–¹æ³•
"""


def stop_recoding():
    global recording_stopped
    recording_stopped = True
    # print("button pressed.\n")


"""
åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶æ–¹æ³•
"""


def delete_temp_file():
    import os
    import glob

    # åˆ—å‡ºç‰¹å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    files = glob.glob('./static/temp/*')

    # éå†åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œå¹¶åˆ é™¤å®ƒ
    for f in files:
        try:
            os.remove(f)
        except OSError as e:
            print(f"Error deleting file {f}: {e}")

    print("ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤")


"""
é•¿æŒ‰æ—¶é€€å‡ºç¨‹åºæ–¹æ³•
"""


def handle_long_press():
    delete_temp_file()
    print("ç¨‹åºé€€å‡ºã€‚")
    # Send a SIGUSER1; this seems to cause signal.pause() to return.
    # å‘é€ SIGUSER1ï¼›è¿™ä¼¼ä¹èƒ½å¤Ÿè®© pause() è¿”å›ã€‚
    os.kill(os.getpid(), signal.SIGUSR1)


"""
stt apiè°ƒç”¨ (whisper)
"""


def stt(file_name):
    audio_file = open(file_name, "rb")
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        response_format="text"
    )
    return transcript


"""
å¯¹è¯æ–¹æ³•
"""


def conversation(msg):
    result = ""

    # ç”Ÿæˆå¯¹è¯
    stream = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=msg,
        stream=True,
    )

    print("ä»–è¯´ï¼š", end="")
    for chunk in stream:
        # å¦‚æœç”Ÿæˆçš„æ–‡æœ¬ä¸ä¸ºç©º
        if chunk.choices[0].delta.content is not None:
            result += chunk.choices[0].delta.content
            print(chunk.choices[0].delta.content, end="")

    print()
    # ç”Ÿæˆçš„æ–‡æœ¬è½¬è¯­éŸ³
    text_to_speech(result)

    msg.append({"role": "assistant", "content": result})

    return msg


def text_to_speech(text):
    # è¿æ¥åˆ°æ•°æ®æº
    response = client.audio.speech.create(
        model="tts-1",
        voice="onyx",
        input=text
    )
    response.stream_to_file('./static/temp/temp_spoke.mp3')

    play_result('./static/temp/temp_spoke.mp3')


"""
ä¸»æ–¹æ³•
"""
if __name__ == "__main__":
    # è®¾ç½®pydubçš„æ—¥å¿—çº§åˆ«ä¸ºé”™è¯¯
    logging.getLogger("pydub.converter").setLevel(logging.INFO)
    # è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡
    os.environ['http_proxy'] = 'http://10.11.171.154:1234'
    os.environ['https_proxy'] = 'http://10.11.171.154:1234'

    # åœæ­¢å½•åˆ¶æ ‡å¿—
    global recording_stopped
    global client

    # åˆå§‹åŒ–å¿…è¦å˜é‡
    client = OpenAI()
    msg = conversation(msg)

    while True:
        # æŒ‰æŒ‰é’®ç»“æŸrecoding äº‹ä»¶
        button.when_pressed = stop_recoding
        # å½“æŒ‰é’®é•¿æŒ‰æ—¶ äº‹ä»¶
        button.when_held = handle_long_press

        recording_stopped = False
        print("ä½ è¯´(æŒ‰ä¸‹æŒ‰é’®ç»“æŸè¯´è¯ï¼Œé•¿æŒ‰æŒ‰é’®ç»“æŸç¨‹åº)ï¼š", end="")
        # å½•åˆ¶æ—¶è‡ªåŠ¨ç”Ÿæˆçš„åŸºäºæ—¶é—´çš„å“ˆå¸Œæ–‡ä»¶åç§°
        file_name = recoding()

        you_say = stt(file_name)
        print(you_say)

        # åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        delete_temp_file()
        msg.append({"role": "user", "content": you_say})
        msg = conversation(msg)

    pause()
